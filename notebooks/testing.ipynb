{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e477d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-05-25 13:02:30,900:jax._src.xla_bridge:967: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import jax.tree_util as jtu\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "from jaxtyping import Array, Float\n",
    "from jax import vmap\n",
    "\n",
    "import diff_ml as dml\n",
    "import diff_ml.nn as dnn\n",
    "from diff_ml.model import Bachelier\n",
    "from diff_ml.nn.utils import init_model_weights, predict\n",
    "from diff_ml.typing import Data\n",
    "\n",
    "from diff_ml.plotting import plot_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6ada8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, batch: Data) -> Float[Array, \"\"]:\n",
    "    xs, ys = batch[\"x\"], batch[\"y\"]\n",
    "    pred_ys = eqx.filter_vmap(model)(xs)\n",
    "    return dml.losses.mse(ys, pred_ys)\n",
    "\n",
    "\n",
    "def eval_fn(model, batch: Data) -> Float[Array, \"\"]:\n",
    "    return jnp.sqrt(loss_fn(model, batch))\n",
    "\n",
    "\n",
    "def train_generator(xs, n_samples: int, n_batch_size: int, *, key):\n",
    "    while True:\n",
    "        key, subkey = jrandom.split(key)\n",
    "\n",
    "        def subset_fn(key):\n",
    "            choice = jrandom.choice(key=key, a=n_samples, shape=(n_batch_size,))\n",
    "\n",
    "            def subset(x):\n",
    "                return x[choice]\n",
    "\n",
    "            return subset\n",
    "\n",
    "        yield jtu.tree_map(subset_fn(subkey), xs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0b42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TracerArrayConversionError",
     "evalue": "The numpy.ndarray conversion method __array__() was called on traced array with shape float32[256,49]\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerArrayConversionError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTracerArrayConversionError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m optim \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39madam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m     59\u001b[0m sobolev_loss_fn \u001b[38;5;241m=\u001b[39m dml\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39msobolev(dml\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mmse, method\u001b[38;5;241m=\u001b[39mdml\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSobolevLossType\u001b[38;5;241m.\u001b[39mSECOND_ORDER_PCA, ref_model\u001b[38;5;241m=\u001b[39mref_model)\n\u001b[0;32m---> 60\u001b[0m surrogate, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mdml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43msurrogate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msobolev_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# visualize predictions of model trained on second order data\u001b[39;00m\n\u001b[1;32m     67\u001b[0m pred_y, pred_dydx, pred_ddyddx \u001b[38;5;241m=\u001b[39m predict(surrogate, test_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/ma/diff-ml-rand-svd/diff_ml/nn/train.py:71\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, train_data, eval_fn, test_data, optim, n_epochs, n_batches_per_epoch)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m islice(train_data, n_batches_per_epoch):\n\u001b[0;32m---> 71\u001b[0m         model, opt_state, train_loss, loss_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# update loss_state\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     loss_state \u001b[38;5;241m=\u001b[39m loss_state\u001b[38;5;241m.\u001b[39mupdate_prev_mean_losses(loss_state\u001b[38;5;241m.\u001b[39maccum_losses \u001b[38;5;241m/\u001b[39m loss_state\u001b[38;5;241m.\u001b[39mcurrent_iter[\u001b[38;5;241m0\u001b[39m])\n",
      "    \u001b[0;31m[... skipping hidden 19 frame]\u001b[0m\n",
      "File \u001b[0;32m~/ma/diff-ml-rand-svd/diff_ml/nn/train.py:41\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, loss_fn, optim, opt_state, batch, loss_state)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_jit\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_step\u001b[39m(model, loss_fn, optim: optax\u001b[38;5;241m.\u001b[39mGradientTransformation, opt_state: PyTree, batch: Data, loss_state: LossState):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Canonical training step for a single batch.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     (loss_value, loss_state), grads \u001b[38;5;241m=\u001b[39m \u001b[43meqx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_value_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     updates, opt_state \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mupdate(grads, opt_state, model)\n\u001b[1;32m     43\u001b[0m     model \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mapply_updates(model, updates)\n",
      "    \u001b[0;31m[... skipping hidden 18 frame]\u001b[0m\n",
      "File \u001b[0;32m~/ma/diff-ml-rand-svd/diff_ml/losses/regression.py:336\u001b[0m, in \u001b[0;36msobolev.<locals>.sobolev_second_order_loss\u001b[0;34m(model, batch, prev_loss_state, ref_model)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# apply PCA to first-order gradients dydx_pred\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# alternatively use dydx of reference model or difference: dydx_pred - dydx\u001b[39;00m\n\u001b[1;32m    333\u001b[0m pca_directions, eval_hvp, k_pc \u001b[38;5;241m=\u001b[39m PCA_of_dydx_directions(dydx_pred)\n\u001b[0;32m--> 336\u001b[0m rand_SVD_directions \u001b[38;5;241m=\u001b[39m \u001b[43mget_rand_SVD_directions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMakeScalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m#### ---- Second-Order Targets via Finite Differences ---- ####\u001b[39;00m\n\u001b[1;32m    342\u001b[0m payoff_fn \u001b[38;5;241m=\u001b[39m partial(ref_model\u001b[38;5;241m.\u001b[39mantithetic_payoff, \u001b[38;5;66;03m# TODO make loss function independent of Bachelier, pass payoff_fn\u001b[39;00m\n\u001b[1;32m    343\u001b[0m                     weights\u001b[38;5;241m=\u001b[39mref_model\u001b[38;5;241m.\u001b[39mweights,\n\u001b[1;32m    344\u001b[0m                     strike_price\u001b[38;5;241m=\u001b[39mref_model\u001b[38;5;241m.\u001b[39mstrike_price\n\u001b[1;32m    345\u001b[0m                     )\n",
      "File \u001b[0;32m~/ma/diff-ml-rand-svd/diff_ml/losses/regression.py:154\u001b[0m, in \u001b[0;36mget_rand_SVD_directions\u001b[0;34m(f, x, k, key)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Step 1: build sketch Y = H @ sketch_directions\u001b[39;00m\n\u001b[1;32m    153\u001b[0m Y \u001b[38;5;241m=\u001b[39m hvp_batch(f\u001b[38;5;241m=\u001b[39mf, inputs\u001b[38;5;241m=\u001b[39mx, directions\u001b[38;5;241m=\u001b[39msketch_directions) \u001b[38;5;66;03m# (batch_size, k, dim)\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m \u001b[43mplot_for_every_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop here\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m#jax.debug.print(\"Y.shape {shape}\", shape=Y.shape)\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# TODO understand if averaging over batch_size is the correct approach\u001b[39;00m\n",
      "File \u001b[0;32m~/ma/diff-ml-rand-svd/diff_ml/losses/regression.py:134\u001b[0m, in \u001b[0;36mplot_for_every_x\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m Y_proj \u001b[38;5;241m=\u001b[39m \u001b[43mPCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_flat\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, 2)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(Y_proj[:, \u001b[38;5;241m0\u001b[39m], Y_proj[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    137\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHessian sketches projected to 2D via PCA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ma/lib/python3.10/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ma/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ma/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:468\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    447\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m     U, S, _, X, x_is_centered, xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n",
      "File \u001b[0;32m~/miniconda3/envs/ma/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:505\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA with svd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for Array API inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    497\u001b[0m     )\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# Validate the data, without ever forcing a copy as any solver that\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# supports sparse input data and the `covariance_eigh` solver are\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# written in a way to avoid the need for any inplace modification of\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# the input data contrary to the other solvers.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# The copy will happen\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# later, only if needed, once the solver negotiation below is done.\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd_solver\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/miniconda3/envs/ma/lib/python3.10/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/ma/lib/python3.10/site-packages/sklearn/utils/validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ma/lib/python3.10/site-packages/sklearn/utils/_array_api.py:839\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 839\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/ma/lib/python3.10/site-packages/jax/_src/core.py:761\u001b[0m, in \u001b[0;36mTracer.__array__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 761\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TracerArrayConversionError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mTracerArrayConversionError\u001b[0m: The numpy.ndarray conversion method __array__() was called on traced array with shape float32[256,49]\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerArrayConversionError"
     ]
    }
   ],
   "source": [
    "# Specify model\n",
    "key = jrandom.key(0)\n",
    "n_dims: int = 7\n",
    "n_samples: int = 8 * 1024\n",
    "key, subkey = jrandom.split(key)\n",
    "weights = jrandom.uniform(subkey, shape=(n_dims,), minval=1.0, maxval=10.0)\n",
    "ref_model = Bachelier(key, n_dims, weights)\n",
    "\n",
    "\n",
    "\n",
    "# Generate data\n",
    "train_ds = ref_model.sample(n_samples)\n",
    "test_ds = ref_model.analytic(n_samples)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "n_batch_size = 256\n",
    "\n",
    "key, subkey = jrandom.split(key)\n",
    "train_gen = train_generator(train_ds, n_samples, n_batch_size, key=subkey)\n",
    "\n",
    "# TODO move to diff_ml/plotting.py\n",
    "# Plot data\n",
    "x_train_mean = jnp.mean(train_ds[\"x\"])\n",
    "x_train_std = jnp.std(train_ds[\"x\"])\n",
    "y_train_mean = jnp.mean(train_ds[\"y\"])\n",
    "y_train_std = jnp.std(train_ds[\"y\"])\n",
    "\n",
    "xs_train = jnp.asarray(train_ds[\"x\"])\n",
    "ys_train = jnp.asarray(train_ds[\"y\"])\n",
    "zs_train = jnp.asarray(train_ds[\"dydx\"])\n",
    "\n",
    "xs_test = jnp.asarray(test_ds[\"x\"])\n",
    "ys_test = jnp.asarray(test_ds[\"y\"])\n",
    "zs_test = jnp.asarray(test_ds[\"dydx\"])\n",
    "\n",
    "baskets = ref_model.baskets(xs_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Specify the surrogate model architecture\n",
    "key, subkey = jrandom.split(key)\n",
    "mlp = eqx.nn.MLP(key=subkey, in_size=n_dims, out_size=\"scalar\", width_size=20, depth=3, activation=jax.nn.silu) # jax.nn.silu\n",
    "\n",
    "key, subkey = jrandom.split(key)\n",
    "mlp = init_model_weights(mlp, jax.nn.initializers.glorot_normal(), key=subkey)\n",
    "\n",
    "surrogate = dnn.Normalized(\n",
    "    dnn.Normalization(x_train_mean, x_train_std), mlp, dnn.Denormalization(y_train_mean, y_train_std)\n",
    ")\n",
    "\n",
    "\n",
    "## Train the surrogate using sobolev loss\n",
    "#optim = optax.adam(learning_rate=1e-3)\n",
    "#sobolev_loss_fn = dml.losses.sobolev(dml.losses.mse, method=dml.losses.SobolevLossType.SECOND_ORDER_PCA, ref_model=ref_model)\n",
    "#surrogate, metrics = dml.train(\n",
    "#    surrogate, sobolev_loss_fn, train_gen, eval_fn, test_ds, optim, n_epochs=n_epochs)\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "## visualize predictions of model trained on second order data\n",
    "#pred_y, pred_dydx, pred_ddyddx = predict(surrogate, test_ds[\"x\"])\n",
    "#plot_eval(pred_y, pred_dydx, pred_ddyddx, test_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c72510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    train_data: DataGenerator,\n",
    "    eval_fn,\n",
    "    test_data: Optional[Data],\n",
    "    optim: optax.GradientTransformation,\n",
    "    n_epochs: int,\n",
    "    n_batches_per_epoch: int = 64,\n",
    ") -> PyTree:\n",
    "    \"\"\"Canonical training loop.\"\"\"\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "    train_loss = jnp.zeros(1)\n",
    "    batch_size = len(next(train_data)[\"x\"])\n",
    "    metrics = {\"train_loss\": jnp.zeros(n_epochs), \"test_loss\": jnp.zeros(n_epochs)}\n",
    "    loss_state = LossState(jnp.array([0.0, 0.0, 1.0]), jnp.array([1/3, 1/3, 1/3]), jnp.array([0.0, 0.0, 1.0]), jnp.array([0.0, 0.0, 0.0]), jnp.array([0.0, 0.0, 0.0])) \n",
    "\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "    for epoch in pbar:\n",
    "        for batch in islice(train_data, n_batches_per_epoch):\n",
    "            model, opt_state, train_loss, loss_state = train_step(model, loss_fn, optim, opt_state, batch, loss_state)\n",
    "\n",
    "\n",
    "        # update loss_state\n",
    "        loss_state = loss_state.update_prev_mean_losses(loss_state.accum_losses / loss_state.current_iter[0])\n",
    "        loss_state = loss_state.update_accum_losses(jnp.zeros(len(loss_state.losses)))\n",
    "        loss_state = loss_state.update_current_iter(jnp.zeros(len(loss_state.losses)))\n",
    "\n",
    "\n",
    "        metrics_update_element(metrics, \"train_loss\", epoch, train_loss)\n",
    "        epoch_stats = f\"Epoch: {epoch:3d} | Train: {train_loss:.5f}\"\n",
    "\n",
    "        if test_data:\n",
    "            test_loss = evaluate(model, test_data, batch_size, eval_fn)\n",
    "            metrics_update_element(metrics, \"test_loss\", epoch, test_loss)\n",
    "            epoch_stats += f\" | Test: {test_loss:.5f}\"\n",
    "\n",
    "        pbar.set_description(epoch_stats)\n",
    "\n",
    "    return model, metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
