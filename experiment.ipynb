{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.stats import norm\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "import jax\n",
    "\n",
    "from typing import Sequence, Callable, Union, Tuple, Optional, Any\n",
    "from jaxtyping import Array, Float, Int, PyTree\n",
    "\n",
    "import equinox as eqx\n",
    "import optax\n",
    "import chex\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return jnp.sin(x)\n",
    "\n",
    "fs = vmap(f)\n",
    "\n",
    "xs = jnp.array([0., jnp.pi / 2, jnp.pi])[..., jnp.newaxis]\n",
    "ys = fs(xs)\n",
    "\n",
    "print(xs.shape)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.000000e+00]\n",
      " [ 1.000000e+00]\n",
      " [-8.742278e-08]]\n",
      "[[ 1.000000e+00]\n",
      " [-4.371139e-08]\n",
      " [-1.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "primals, f_jvp = jax.jvp(f, (xs,), (jnp.ones_like(xs),))\n",
    "print(primals)\n",
    "print(f_jvp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "key, subkey = random.split(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear(eqx.Module):\n",
    "    weight: Array\n",
    "    bias: Array\n",
    "\n",
    "    def __init__(self, in_size, out_size, key):\n",
    "        wkey, bkey = jax.random.split(key)\n",
    "        self.weight = jax.random.normal(wkey, (out_size, in_size))\n",
    "        self.bias = jax.random.normal(bkey, (out_size,))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.weight @ x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hvp(f, primals, tangents):\n",
    "    return jax.jvp(jax.grad(f), primals, tangents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def f(x):\n",
    "#   return jnp.asarray(\n",
    "#     [x[0], 5*x[2], 4*x[1]**2 - 2*x[2], x[2] * jnp.sin(x[0])])\n",
    "def f(X):\n",
    "    # return jnp.asarray([jnp.sin(x)])\n",
    "    return (jnp.sum(jnp.sin(X) ** 2),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacrev_and_vjp(fun: Callable, argnums: Union[int, Sequence[int]] = 0,\n",
    "           has_aux: bool = False, holomorphic: bool = False, allow_int: bool = False) -> Callable:\n",
    "  \"\"\"Jacobian of ``fun`` evaluated row-by-row using reverse-mode AD.\n",
    "\n",
    "  Args:\n",
    "    fun: Function whose Jacobian is to be computed.\n",
    "    argnums: Optional, integer or sequence of integers. Specifies which\n",
    "      positional argument(s) to differentiate with respect to (default ``0``).\n",
    "    has_aux: Optional, bool. Indicates whether ``fun`` returns a pair where the\n",
    "      first element is considered the output of the mathematical function to be\n",
    "      differentiated and the second element is auxiliary data. Default False.\n",
    "    holomorphic: Optional, bool. Indicates whether ``fun`` is promised to be\n",
    "      holomorphic. Default False.\n",
    "    allow_int: Optional, bool. Whether to allow differentiating with\n",
    "      respect to integer valued inputs. The gradient of an integer input will\n",
    "      have a trivial vector-space dtype (float0). Default False.\n",
    "\n",
    "  Returns:\n",
    "    A function with the same arguments as ``fun``, that evaluates the Jacobian of\n",
    "    ``fun`` using reverse-mode automatic differentiation. If ``has_aux`` is True\n",
    "    then a pair of (jacobian, auxiliary_data) is returned.\n",
    "\n",
    "  >>> import jax\n",
    "  >>> import jax.numpy as jnp\n",
    "  >>>\n",
    "  >>> def f(x):\n",
    "  ...   return jnp.asarray(\n",
    "  ...     [x[0], 5*x[2], 4*x[1]**2 - 2*x[2], x[2] * jnp.sin(x[0])])\n",
    "  ...\n",
    "  >>> print(jax.jacrev(f)(jnp.array([1., 2., 3.])))\n",
    "  [[ 1.       0.       0.     ]\n",
    "   [ 0.       0.       5.     ]\n",
    "   [ 0.      16.      -2.     ]\n",
    "   [ 1.6209   0.       0.84147]]\n",
    "  \"\"\"\n",
    "\n",
    "  docstr = (\"Jacobian of {fun} with respect to positional argument(s) \"\n",
    "            \"{argnums}. Takes the same arguments as {fun} but returns the \"\n",
    "            \"jacobian of the output with respect to the arguments at \"\n",
    "            \"positions {argnums}.\")\n",
    "\n",
    "  def jacfun(*args, **kwargs):\n",
    "    f = jax.scipy.linalg.lu.wrap_init(fun, kwargs)\n",
    "    f_partial, dyn_args = argnums_partial(f, argnums, args,\n",
    "                                          require_static_args_hashable=False)\n",
    "    tree_map(partial(_check_input_dtype_jacrev, holomorphic, allow_int), dyn_args)\n",
    "    if not has_aux:\n",
    "      y, pullback = _vjp(f_partial, *dyn_args)\n",
    "    else:\n",
    "      y, pullback, aux = _vjp(f_partial, *dyn_args, has_aux=True)\n",
    "    tree_map(partial(_check_output_dtype_jacrev, holomorphic), y)\n",
    "    jac = vmap(pullback)(_std_basis(y))\n",
    "    jac = jac[0] if isinstance(argnums, int) else jac\n",
    "    example_args = dyn_args[0] if isinstance(argnums, int) else dyn_args\n",
    "    jac_tree = tree_map(partial(_jacrev_unravel, y), example_args, jac)\n",
    "    jac_tree = tree_transpose(tree_structure(example_args), tree_structure(y), jac_tree)\n",
    "    if not has_aux:\n",
    "      return jac_tree, _vjp\n",
    "    else:\n",
    "      return jac_tree, _vjp, aux\n",
    "\n",
    "  return jacfun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of cotangent input to vjp pullback function (3,) must be the same as the shape of corresponding primal input (1,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[326], line 22\u001b[0m\n\u001b[0;32m     16\u001b[0m primals, vjp_fun \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mvjp(model, X)\n\u001b[0;32m     17\u001b[0m \u001b[39m# J, = vmap(vjp_fun)(jnp.eye(len(X)))\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[39m# hesse_vector\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m a, b \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mjvp(vjp_fun, (X,), (jnp\u001b[39m.\u001b[39;49mones_like(X),))\n\u001b[0;32m     24\u001b[0m \u001b[39m# greeks = jax.jacrev(f)(X)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[39m# greeks, = f_vjp(jnp.ones_like(primals))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m# t_greeks, = vmap(f_vjp)(jnp.eye(3))\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39m# second = jax.jvp(f_vjp, (X,))\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m80\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\neilk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\jax\\_src\\api.py:2408\u001b[0m, in \u001b[0;36mjvp\u001b[1;34m(fun, primals, tangents, has_aux)\u001b[0m\n\u001b[0;32m   2370\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Computes a (forward-mode) Jacobian-vector product of ``fun``.\u001b[39;00m\n\u001b[0;32m   2371\u001b[0m \n\u001b[0;32m   2372\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2405\u001b[0m \u001b[39m0.19900084\u001b[39;00m\n\u001b[0;32m   2406\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2407\u001b[0m _check_callable(fun)\n\u001b[1;32m-> 2408\u001b[0m \u001b[39mreturn\u001b[39;00m _jvp(lu\u001b[39m.\u001b[39;49mwrap_init(fun), primals, tangents, has_aux\u001b[39m=\u001b[39;49mhas_aux)\n",
      "File \u001b[1;32mc:\\Users\\neilk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\jax\\_src\\api.py:2437\u001b[0m, in \u001b[0;36m_jvp\u001b[1;34m(fun, primals, tangents, has_aux)\u001b[0m\n\u001b[0;32m   2435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_aux:\n\u001b[0;32m   2436\u001b[0m   flat_fun, out_tree \u001b[39m=\u001b[39m flatten_fun_nokwargs(fun, tree_def)\n\u001b[1;32m-> 2437\u001b[0m   out_primals, out_tangents \u001b[39m=\u001b[39m ad\u001b[39m.\u001b[39;49mjvp(flat_fun)\u001b[39m.\u001b[39;49mcall_wrapped(ps_flat, ts_flat)\n\u001b[0;32m   2438\u001b[0m   out_tree \u001b[39m=\u001b[39m out_tree()\n\u001b[0;32m   2439\u001b[0m   \u001b[39mreturn\u001b[39;00m (tree_unflatten(out_tree, out_primals),\n\u001b[0;32m   2440\u001b[0m           tree_unflatten(out_tree, out_tangents))\n",
      "File \u001b[1;32mc:\\Users\\neilk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\jax\\linear_util.py:167\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m gen \u001b[39m=\u001b[39m gen_static_args \u001b[39m=\u001b[39m out_store \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m   ans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m    168\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m   \u001b[39m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[0;32m    170\u001b[0m   \u001b[39m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[0;32m    171\u001b[0m   \u001b[39m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[0;32m    172\u001b[0m   \u001b[39m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[0;32m    173\u001b[0m   \u001b[39m# state.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m   \u001b[39mwhile\u001b[39;00m stack:\n",
      "File \u001b[1;32mc:\\Users\\neilk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\jax\\_src\\tree_util.py:301\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m--> 301\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\neilk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\jax\\_src\\api.py:2578\u001b[0m, in \u001b[0;36m_vjp_pullback_wrapper\u001b[1;34m(name, cotangent_dtypes, cotangent_shapes, io_tree, fun, *py_args_)\u001b[0m\n\u001b[0;32m   2573\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2574\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mType of cotangent input to vjp pullback function (\u001b[39m\u001b[39m{\u001b[39;00mct_dtype\u001b[39m}\u001b[39;00m\u001b[39m) is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2575\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe expected tangent type (\u001b[39m\u001b[39m{\u001b[39;00mexpected_tangent_dtype\u001b[39m}\u001b[39;00m\u001b[39m) of corresponding primal output \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2576\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwith dtype \u001b[39m\u001b[39m{\u001b[39;00m_dtype(arg)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2577\u001b[0m   \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mshape(arg) \u001b[39m!=\u001b[39m ct_shape:\n\u001b[1;32m-> 2578\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2579\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of cotangent input to vjp pullback function \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mshape(arg)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2580\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmust be the same as the shape of corresponding primal input \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2581\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mct_shape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2582\u001b[0m ans \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39margs)\n\u001b[0;32m   2583\u001b[0m \u001b[39mreturn\u001b[39;00m tree_unflatten(out_tree, ans)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of cotangent input to vjp pullback function (3,) must be the same as the shape of corresponding primal input (1,)."
     ]
    }
   ],
   "source": [
    "key, subkey = random.split(key, 2)\n",
    "model = eqx.nn.MLP(key=subkey, in_size=3, out_size=1, width_size=20, depth=3, activation=jax.nn.elu)\n",
    "\n",
    "# X = random.normal(subkey1, (3,4))\n",
    "# V = random.normal(subkey2, (3,4))\n",
    "# V = jnp.ones((3,4))\n",
    "\n",
    "# res = hvp(f, (X,), (V,))\n",
    "\n",
    "# X = random.normal(subkey1, (3,))\n",
    "X = jnp.ones((3,)) * jnp.pi / 2\n",
    "V = jnp.ones_like(X)\n",
    "\n",
    "# X = X[..., jnp.newaxis]\n",
    "\n",
    "primals, vjp_fun = jax.vjp(model, X)\n",
    "# J, = vmap(vjp_fun)(jnp.eye(len(primals)))\n",
    "\n",
    "\n",
    "# hesse_vector\n",
    "\n",
    "a, b = jax.jvp(vjp_fun, (X,), (jnp.ones_like(X),))\n",
    "\n",
    "# greeks = jax.jacrev(f)(X)\n",
    "\n",
    "# greeks, = f_vjp(jnp.ones_like(primals))\n",
    "\n",
    "# primals, greeks = mjp(f, X, jnp.ones_like(primals))\n",
    "\n",
    "\n",
    "# t_greeks, = vmap(f_vjp)(jnp.eye(3))\n",
    "# second = jax.jvp(f_vjp, (X,))\n",
    "\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(primals.shape)\n",
    "print(primals)\n",
    "print(J)\n",
    "# print(vmap(f_vjp)(jnp.eye(1)))\n",
    "print(\"-\" * 80)\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(res[0].shape)\n",
    "print(res[1].shape)\n",
    "# print(res.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray(1., dtype=float32, weak_type=True),\n",
       " DeviceArray(-4.371139e-08, dtype=float32, weak_type=True))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.jvp(jnp.sin, (jnp.pi / 2, ), (1.0, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20363042]\n",
      "[[0.20363042]\n",
      " [0.20618227]\n",
      " [0.20519818]]\n",
      "test\n",
      "[0.01606509]\n",
      "[[ 0.01606509]\n",
      " [-0.00216613]\n",
      " [ 0.00098517]]\n",
      "[[[[ 0.01606509]\n",
      "   [ 0.        ]\n",
      "   [ 0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.        ]\n",
      "   [-0.00216612]\n",
      "   [ 0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.        ]\n",
      "   [ 0.        ]\n",
      "   [ 0.00098517]]]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument '<function f at 0x0000020EB29E5550>' of type <class 'function'> is not a valid JAX type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m X \u001b[39m=\u001b[39m xs_train\n\u001b[0;32m     26\u001b[0m Y \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mones_like(xs_train)\n\u001b[1;32m---> 27\u001b[0m res \u001b[39m=\u001b[39m hvp(f, (X, ), (Y, ))\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(res)\n\u001b[0;32m     29\u001b[0m \u001b[39m# vmap(grad(model))(jnp.array([1.0]))\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[39m# primals, f_vjp = eqx.filter_vjp(model, jnp.array([1.0]))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[39m# vmap(model)(x_test)\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\neilk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\jax\\_src\\api.py:3084\u001b[0m, in \u001b[0;36m_check_arg\u001b[1;34m(arg)\u001b[0m\n\u001b[0;32m   3082\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_arg\u001b[39m(arg):\n\u001b[0;32m   3083\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(arg, core\u001b[39m.\u001b[39mTracer) \u001b[39mor\u001b[39;00m _valid_jaxtype(arg)):\n\u001b[1;32m-> 3084\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mArgument \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00marg\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(arg)\u001b[39m}\u001b[39;00m\u001b[39m is not a valid JAX type.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument '<function f at 0x0000020EB29E5550>' of type <class 'function'> is not a valid JAX type."
     ]
    }
   ],
   "source": [
    "class MakeScalar(eqx.Module):\n",
    "    model: eqx.Module\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        out = self.model(*args, **kwargs)\n",
    "        return jnp.reshape(out, ())\n",
    "\n",
    "model = eqx.nn.MLP(key=subkey, in_size=1, out_size=1, width_size=20, depth=3, activation=jax.nn.elu)\n",
    "print(model(jnp.array([1.0])))\n",
    "\n",
    "\n",
    "xs_train = jnp.array([[1.0], [2.0], [3.0]])\n",
    "print(vmap(model)(xs_train))\n",
    "\n",
    "print(\"test\")\n",
    "g_model = grad(MakeScalar(model))\n",
    "\n",
    "print(g_model(jnp.array([1.0])))\n",
    "print(vmap(g_model)(xs_train))\n",
    "\n",
    "\n",
    "test = jax.jacrev(vmap(model))(jnp.array([[1.0], [2.0], [3.0]]))\n",
    "print(test)\n",
    "\n",
    "X = xs_train\n",
    "Y = jnp.ones_like(xs_train)\n",
    "res = hvp(f, (X, ), (Y, ))\n",
    "print(res)\n",
    "# vmap(grad(model))(jnp.array([1.0]))\n",
    "\n",
    "# primals, f_vjp = eqx.filter_vjp(model, jnp.array([1.0]))\n",
    "\n",
    "# print(primals)\n",
    "# jax.jacrev(f)(jnp.array([1.0, 2.0, 3.0]))\n",
    "\n",
    "# res = jax.jacobian(vmap(model))(jnp.array([0.0, jnp.pi/2, jnp.pi, 2*jnp.pi]))\n",
    "# res = vmap(jax.jacobian(model))(jnp.array([0.0, jnp.pi/2]))\n",
    "\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "\n",
    "\n",
    "# model = eqx.nn.MLP(key=subkey, in_size=1, out_size=1, width_size=20, depth=3, activation=jax.nn.elu)\n",
    "\n",
    "# print(model(jnp.array([1.0])).shape)\n",
    "# x_test = jnp.array([[1.0], [2.0]])\n",
    "\n",
    "# vmap(model)(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model: eqx.nn.MLP, x: Float[Array, \"batch\"], y: Float[Array, \"batch\"]) -> Float[Array, \"\"]:\n",
    "    pred_y = vmap(model)(x)\n",
    "    return jnp.mean((y - pred_y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[ 0.00450898]],\n",
       "\n",
       "             [[-0.00172892]],\n",
       "\n",
       "             [[ 0.00161424]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmap(jax.jacrev(model))(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(8.742278e-08, dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.hessian(f)(jnp.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(-8.742278e-08, dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sin(jnp.pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
